# Deployment Architecture & Flow Diagram

## Complete System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DEVELOPER WORKFLOW                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Developer creates feature branch and commits code
   â””â”€> git checkout -b feature/my-feature
       git add .
       git commit -m "Feature: Add new capability"
       git push origin feature/my-feature

2. Developer creates Pull Request on GitHub
   â””â”€> gh pr create --title "My Feature"
       â””â”€> PR appears at: https://github.com/YOUR_ORG/ai-release-guardian/pull/X

3. GitHub webhook triggers immediately on PR open
   â””â”€> Event: pull_request opened
       â””â”€> Webhook URL: GitHub Actions (built-in)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GITHUB ACTIONS WORKFLOW TRIGGER                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Workflow: phase2-release-guardian.yml
Location: .github/workflows/phase2-release-guardian.yml
Trigger: Pull request opened/updated/reopened
Runner: ubuntu-latest


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1: TEST GENERATION JOB                         â”‚
â”‚                     (Runs on: ubuntu-latest)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Job: phase1-test-generation
Duration: 30-60 seconds

Steps:
1. Checkout code
   â””â”€> actions/checkout@v3 (fetch full history)

2. Setup Python 3.11
   â””â”€> actions/setup-python@v4
   â””â”€> With caching (pip cache)

3. Install dependencies
   â””â”€> pip install -r requirements.txt

4. Generate tests & score risk
   â””â”€> python -m src.agents.phase2_orchestrator generate-tests
   â””â”€> Uses: Planner, TestGenerator, RiskScorer agents
   â””â”€> Inputs: GitHub PR analysis + Jira AC extraction
   â””â”€> Outputs: 
       â”œâ”€ tests_generated.json (test scenarios)
       â”œâ”€ risk_assessment.json (risk score + flags)
       â””â”€ Artifacts uploaded

Flow:
   [GitHub PR diff] â†’ [Planner] â†’ [Analyze changes]
        â†“
   [Jira AC] â†’ [Extract requirements]
        â†“
   [TestGenerator] â†’ [Generate test scenarios via Claude]
        â†“
   [RiskScorer] â†’ [Score risk level 0-100]
        â†“
   [tests_generated.json] â†’ [Upload artifact]


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 2A: TEST EXECUTION JOB                         â”‚
â”‚              (Runs after Phase 1 successfully completes)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Job: phase2-execute-tests
Depends on: phase1-test-generation
Duration: 60-120 seconds

Steps:
1. Checkout code

2. Setup Python & install dependencies
   â””â”€> pip install -r requirements.txt
   â””â”€> pip install pytest pytest-cov pytest-json-report

3. Execute tests
   â””â”€> python -m src.agents.phase2_orchestrator execute-tests
   â””â”€> Agent: TestExecutionAgent
   â””â”€> Runs: pytest tests/ with JSON reporting
   â””â”€> Captures:
       â”œâ”€ Total tests
       â”œâ”€ Passed/Failed/Errors
       â”œâ”€ Pass rate %
       â”œâ”€ Execution time
       â””â”€ Coverage metrics

Flow:
   [Download artifact: tests_generated.json]
        â†“
   [Run pytest] â†’ [Parse JSON report]
        â†“
   [Results: Pass/Fail/Error]
        â†“
   [tests_executed.json] â†’ [Upload artifact]


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 2B: TEST VALIDATION JOB                         â”‚
â”‚             (Runs after Phase 2 Execute successfully completes)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Job: phase2-validate-tests
Depends on: phase2-execute-tests
Duration: 10-20 seconds

Steps:
1. Download artifacts (tests_generated.json, tests_executed.json)

2. Validate tests
   â””â”€> python -m src.agents.phase2_orchestrator validate-tests
   â””â”€> Agent: TestValidationAgent
   â””â”€> Validates:
       â”œâ”€ AC coverage % (target: â‰¥80%)
       â”œâ”€ Map tests to AC
       â”œâ”€ Identify coverage gaps
       â””â”€ Validate test assertions

Flow:
   [Test results] + [Acceptance Criteria from Jira]
        â†“
   [Match test names to AC]
        â†“
   [Calculate coverage %]
        â”œâ”€ If â‰¥80%: Coverage PASS
        â””â”€ If <80%: Coverage FAIL (gaps identified)
        â†“
   [tests_validated.json] â†’ [Upload artifact]


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 2C: DEPLOYMENT DECISION JOB                     â”‚
â”‚             (Runs after Phase 2 Validate successfully completes)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Job: phase2-deployment-decision
Depends on: phase2-validate-tests
Duration: 5-10 seconds

Steps:
1. Download all artifacts

2. Make deployment decision
   â””â”€> python -m src.agents.phase2_orchestrator make-decision
   â””â”€> Agent: DeploymentDecisionAgent
   â””â”€> Decision Logic (7-tier):

Decision Logic Flow:
   
   1. Tests FAILED?
      â”œâ”€ YES â†’ NO-GO âŒ (confidence 0%)
      â””â”€ NO â†’ Continue to 2

   2. AC Coverage < 80%?
      â”œâ”€ YES â†’ NO-GO âŒ (confidence 0%)
      â””â”€ NO â†’ Continue to 3

   3. Validation FAILED?
      â”œâ”€ YES â†’ NO-GO âŒ (confidence 0%)
      â””â”€ NO â†’ Continue to 4

   4. Risk â‰¥75 (CRITICAL)?
      â”œâ”€ YES â†’ NO-GO âŒ (confidence 10%)
      â””â”€ NO â†’ Continue to 5

   5. Risk â‰¥50 + Database changes?
      â”œâ”€ YES â†’ GATE âš ï¸  (confidence 40%, gate: DBA_REVIEW)
      â””â”€ NO â†’ Continue to 6

   6. Risk â‰¥50 + other changes?
      â”œâ”€ YES â†’ GATE âš ï¸  (confidence 55%, gate: MANUAL_TESTING)
      â””â”€ NO â†’ Continue to 7

   7. All criteria pass?
      â”œâ”€ YES â†’ GO âœ… (confidence = pass_rate Ã— coverage Ã— 100)
      â””â”€ Should not reach here

Output:
   â”œâ”€ status: GO|GATE|NO-GO
   â”œâ”€ confidence: 0-100%
   â”œâ”€ reasoning: List of factors
   â”œâ”€ deployment_gates: Required approvals
   â”œâ”€ recommendation: Action to take
   â””â”€ next_steps: Step-by-step instructions


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 2D: POST DECISION ACTIONS                      â”‚
â”‚                  (Conditional based on decision status)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Action 1: POST DECISION COMMENT TO PR
   â””â”€> All decisions (GO/GATE/NO-GO)
   â””â”€> Action: github-script
   â””â”€> Posts formatted comment with:
       â”œâ”€ Decision status with emoji
       â”œâ”€ Tests executed count
       â”œâ”€ AC coverage %
       â”œâ”€ Risk assessment
       â”œâ”€ Reasoning
       â”œâ”€ Required gates (if any)
       â”œâ”€ Recommendation
       â””â”€ Next steps

   Example Comment:
   ```
   âœ… Phase 2 - AI Release Guardian Auto-QA
   
   **Decision:** GO (Confidence: 92%)
   
   ğŸ§ª Tests Generated
   - Integration: 3
   - Automation: 2
   - E2E: 1
   - Total: 6
   
   âœ… Test Validation
   - AC Coverage: 85%
   - Status: PASS
   
   ğŸ“Š Risk Assessment
   - Risk Score: 38/100 (LOW)
   - Risk Flags: None
   
   ğŸ’¡ Reasoning
   - 6/6 tests passed (100%)
   - 85% AC coverage â‰¥80% threshold
   - Risk score 38/100 (LOW) - no concerns
   
   ğŸ¯ Recommendation
   Deploy to production immediately. Auto-merge enabled.
   ```

Action 2: AUTO-MERGE (if GO decision)
   â””â”€> Condition: status == "GO"
   â””â”€> Action: Auto-merge PR
   â””â”€> Method: squash merge
   â””â”€> Result: PR merged automatically

Action 3: BLOCK MERGE (if NO-GO decision)
   â””â”€> Condition: status == "NO-GO"
   â””â”€> Action: Exit with error code 1
   â””â”€> Result: GitHub prevents merge

Action 4: WAIT FOR APPROVAL (if GATE decision)
   â””â”€> Condition: status == "GATE"
   â””â”€> Action: Post gates in comment
   â””â”€> Result: Manual approval required


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 2E: RESULTS PUBLICATION                         â”‚
â”‚                  (Runs after all jobs complete)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Job: publish-results
Runs: Always (even if previous jobs fail)

Actions:
1. Download all artifacts
2. Display summary in job logs
3. Make artifacts available for download
4. Send notifications (optional)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WORKFLOW COMPLETION OUTCOMES                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Scenario 1: GO Decision âœ…
   â”œâ”€ All tests passed
   â”œâ”€ AC coverage â‰¥80%
   â”œâ”€ Risk score low
   â”œâ”€ PR auto-merged
   â””â”€ Code automatically deployed to staging

Scenario 2: GATE Decision âš ï¸
   â”œâ”€ Tests passed but risk detected
   â”œâ”€ PR comment posts required gates
   â”œâ”€ Merge blocked until approved
   â”œâ”€ Team must approve gates (DBA, manual testing, etc.)
   â””â”€ After approval, manual merge or re-push

Scenario 3: NO-GO Decision âŒ
   â”œâ”€ Tests failed OR coverage <80% OR critical risk
   â”œâ”€ PR comment lists all failures
   â”œâ”€ Merge blocked
   â”œâ”€ Developer must fix issues
   â””â”€ On new push, workflow re-runs


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AWS LAMBDA DEPLOYMENT                              â”‚
â”‚                    (Optional webhook integration)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Deployment:
1. SAM template (lambda/template.yaml)
2. Build: sam build
3. Deploy: sam deploy
4. Result: Lambda function + API Gateway

GitHub Webhook Integration:
   [GitHub Event] â†’ [Webhook POST to API Gateway]
                        â†“
                   [Lambda Function]
                        â†“
                   [Handler invokes agents]
                        â†“
                   [Results posted to GitHub]

Lambda Handler Flow:
   [GitHub webhook payload]
        â†“
   [Extract PR info]
        â†“
   [Invoke Phase 1 agents]
        â”œâ”€ Planner
        â”œâ”€ TestGenerator
        â”œâ”€ RiskScorer
        â””â”€ Rollback (optional)
        â†“
   [Post analysis to PR]
        â†“
   [Return response to GitHub]


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      COMPLETE DATA FLOW                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PR Created
   â†“
[1] GitHub Actions triggered
   â”œâ”€ Checkout code
   â”œâ”€ Setup environment
   â””â”€ Install dependencies
   â†“
[2] PHASE 1 - Test Generation
   â”œâ”€ Analyze PR diff
   â”œâ”€ Extract Jira AC
   â”œâ”€ Generate test scenarios
   â”œâ”€ Score risk
   â””â”€ Output: tests_generated.json
   â†“
[3] PHASE 2A - Test Execution
   â”œâ”€ Run pytest
   â”œâ”€ Parse results
   â”œâ”€ Capture coverage
   â””â”€ Output: tests_executed.json
   â†“
[4] PHASE 2B - Test Validation
   â”œâ”€ Validate AC coverage
   â”œâ”€ Identify gaps
   â”œâ”€ Calculate statistics
   â””â”€ Output: tests_validated.json
   â†“
[5] PHASE 2C - Deployment Decision
   â”œâ”€ Evaluate all criteria
   â”œâ”€ Apply decision logic
   â”œâ”€ Score confidence
   â””â”€ Output: deployment_decision.json
   â†“
[6] Post Results
   â”œâ”€ Comment on PR
   â”œâ”€ Auto-merge if GO
   â”œâ”€ Block if NO-GO
   â””â”€ Gate if GATE
   â†“
PR Status Updated
   â””â”€ Decision visible to developer


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MONITORING & METRICS                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Collect:
â”œâ”€ Workflow execution time (target: <3 min)
â”œâ”€ Test coverage % (target: â‰¥80%)
â”œâ”€ Pass rate % (target: â‰¥95%)
â”œâ”€ Decision distribution (GO/GATE/NO-GO)
â”œâ”€ Auto-merge rate (target: â‰¥90%)
â”œâ”€ Average PR time-to-merge (target: <5 min)
â””â”€ Cost savings vs manual QA

Track Over Time:
â”œâ”€ Decision accuracy (AI vs actual outcomes)
â”œâ”€ Risk score correlation (does high risk = more bugs?)
â”œâ”€ Team feedback on thresholds
â””â”€ Iterate on decision logic


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SUCCESS INDICATORS                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… System is working if:
   â”œâ”€ GitHub Actions workflow triggers on every PR
   â”œâ”€ All 5 jobs complete successfully
   â”œâ”€ PR comment appears with decision (GO/GATE/NO-GO)
   â”œâ”€ GO decisions result in auto-merge
   â”œâ”€ NO-GO decisions block merge
   â”œâ”€ GATE decisions post gates and block merge
   â”œâ”€ Workflow completes in <3 minutes
   â”œâ”€ All agents execute without errors
   â”œâ”€ Coverage metrics calculated correctly
   â””â”€ Decisions match expected outcomes

```

---

## Timeline Overview

```
T+0s:   PR created â†’ GitHub Actions triggered
T+10s:  Phase 1 starts (test generation)
T+60s:  Phase 2A starts (test execution)
T+120s: Phase 2B starts (test validation)
T+130s: Phase 2C starts (deployment decision)
T+140s: Post decision and auto-merge (if GO)
T+150s: Workflow complete, results available

Total: ~2.5 minutes end-to-end
```

---

## Component Interactions

```
GitHub
  â”œâ”€ Stores code
  â”œâ”€ Runs Actions workflow
  â”œâ”€ Receives webhook (optional)
  â””â”€ Posts PR comments

Workflow
  â”œâ”€ Phase 1 Agents
  â”‚  â”œâ”€ Planner (PR analysis)
  â”‚  â”œâ”€ TestGenerator (AI-powered)
  â”‚  â””â”€ RiskScorer (AI-powered)
  â”‚
  â”œâ”€ Phase 2 Agents
  â”‚  â”œâ”€ TestExecutor (pytest)
  â”‚  â”œâ”€ TestValidator (AC coverage)
  â”‚  â””â”€ DeploymentDecider (GO/GATE/NO-GO)
  â”‚
  â””â”€ Orchestrator
     â””â”€ Coordinates all agents

AWS (Optional)
  â”œâ”€ Lambda (webhook handler)
  â”œâ”€ API Gateway (HTTPS endpoint)
  â””â”€ CloudFormation (infrastructure)

External APIs
  â”œâ”€ GitHub API (fetch PR info)
  â”œâ”€ Jira API (fetch AC)
  â””â”€ Claude API (AI analysis)
```

---

**Architecture Version:** 2.0 (Phase 1 + Phase 2)
**Date:** February 2026
**Status:** Ready for Production Deployment
